{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9b8113-c0a9-4bf9-afdf-70835da29e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cc3476-71c3-4525-a096-6476b81afd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "docs_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a47413-d09d-4d52-b022-0c8e89bc310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course in docs_raw:\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e6137c-1c71-4352-8110-8afd01b0f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "qd_client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c8d625-a865-4e0a-9a30-55a893ac8292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=None, indexed_vectors_count=0, points_count=948, segments_count=2, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=512, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=StrictModeConfigOutput(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None)), payload_schema={'course': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=948)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "collection_name = \"zoomcamp-rag\"\n",
    "qd_client.get_collection(collection_name= collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116627e5-f6d9-43b2-a47e-2767d3e189f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_course(query, course, limit=3):\n",
    "    \n",
    "    if course == None:\n",
    "        course_list = ['machine-learning-zoomcamp', 'data-engineering-zoomcamp', 'mlops-zoomcamp']\n",
    "    else:\n",
    "        course_list = [course]\n",
    "        \n",
    "    results = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        query_filter=models.Filter( # filter by course name\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchAny(any=course_list)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ee61d9-5cb7-462d-9566-d9184dbc6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "        You're a course teacher assistant. Answer the question based on the context.\n",
    "        Use only the facts from the context. If relevant information is missing, say you do not know.\n",
    "        Question:\n",
    "        {query}\n",
    "        Context:\n",
    "        {context}\n",
    "        \"\"\".strip()\n",
    "    context = \"\"\n",
    "    for doc in search_results.points:\n",
    "        context += f\"section: {doc.payload['section']}\\nanswer:{doc.payload['text']}\\n\\n\"\n",
    "    return prompt_template.format(query=query, context=context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e08f1432-5543-4ae4-899f-f245b237d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(client, prompt, model='gpt-4.1-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{'role': 'user', 'content': prompt }]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f81fab-c77e-4145-8439-9f0b71d27aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, course= None, verbose_search= False, verbose_prompt = False):\n",
    "    search_results = search_in_course(q, course)\n",
    "    if verbose_search:\n",
    "        print(search_results.points)\n",
    "    prompt = build_prompt(q,search_results)\n",
    "    if verbose_prompt:\n",
    "        print(prompt)\n",
    "    message = llm(openai_client, prompt)\n",
    "    return(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dff30bcf-ae98-44d5-a5ce-5fa6a68d404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ScoredPoint(id=295, version=0, score=0.9089782, payload={'text': 'Before you can develop some data model on dbt, you should create development environment and set some parameter on it. After the model being developed, we should also create deployment environment to create and run some jobs.', 'section': 'Module 4: analytics engineering with dbt', 'course': 'data-engineering-zoomcamp'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=304, version=0, score=0.8591342, payload={'text': 'When running trying to run the dbt project on prod there is some things you need to do and check on your own:\\nFirst Make the pull request and Merge the branch into the main.\\nMake sure you have the latest version, if you made changes to the repo in another place.\\nCheck if the dbt_project.yml file is accessible to the project, if not check this solution (Dbt: This dbt Cloud run was cancelled because a valid dbt project was not found.).\\nCheck if the name you gave to the dataset on BigQuery is the same you put on the dataset spot on the production environment created on dbt cloud.', 'section': 'Module 4: analytics engineering with dbt', 'course': 'data-engineering-zoomcamp'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=312, version=0, score=0.8452531, payload={'text': 'Ans: Dbt provides a mechanism called \"ref\" to manage dependencies between models. By referencing other models using the \"ref\" keyword in SQL, dbt automatically understands the dependencies and ensures the correct execution order.\\nLoading FHV Data goes into slumber using Mage?\\nTry loading the data using jupyter notebooks in a local environment. There might be bandwidth issues with Mage.\\nLoad the data into a pandas dataframe using the urls, make necessary transformations, upload the gcp bucket / alternatively download the parquet/csv files locally and then upload to GCP manually.\\nRegion Mismatch in DBT and BigQuery\\nIf you are using the datasets copied into BigQuery from BigQuery public datasets, the region will be set as US by default and hence it is much easier to set your dbt profile location as US while transforming the tables and views. \\nYou can change the location as follows:', 'section': 'Module 4: analytics engineering with dbt', 'course': 'data-engineering-zoomcamp'}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    }
   ],
   "source": [
    "q = \"How to build model on dbt project?\"\n",
    "output = rag(q, verbose_prompt=False, verbose_search = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55f8bbbd-6429-4c11-ba28-558e155a7628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To build a model on a dbt project, you should follow these steps based on the provided context:\n",
      "\n",
      "1. **Set up your development environment** and configure necessary parameters before starting to develop the data model.\n",
      "2. **Develop the model** within this environment.\n",
      "3. After development, **create a deployment environment** to schedule and run dbt jobs.\n",
      "4. When ready to deploy to production, do the following:\n",
      "   - Make a pull request and merge your branch into the main branch.\n",
      "   - Ensure you have the latest version of the project (especially if changes were made elsewhere).\n",
      "   - Verify that the `dbt_project.yml` file is accessible to the project.\n",
      "   - Confirm that the dataset name you specified in BigQuery matches the dataset configured in the production environment on dbt Cloud.\n",
      "5. Use dbtâ€™s **\"ref\" keyword** in your SQL models to manage dependencies between models. This helps dbt understand execution order automatically.\n",
      "\n",
      "This is the process based on the available information from the context.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209783b8-22cd-4aeb-ae35-e4b0b6fd9275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

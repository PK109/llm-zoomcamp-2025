{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9b8113-c0a9-4bf9-afdf-70835da29e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cc3476-71c3-4525-a096-6476b81afd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../documents.json', 'rt') as f:\n",
    "    docs_raw = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a47413-d09d-4d52-b022-0c8e89bc310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course in docs_raw:\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cea686a-99a3-4b2a-a342-7207964dd2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7134bc9845f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e6137c-1c71-4352-8110-8afd01b0f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f3d4d0-27f1-4f4e-b680-952ab8c33623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, index=index, filter_dict = 'data-engineering-zoomcamp'):\n",
    "    boost = {'question': 3.0, 'section':0.5}\n",
    "    data = index.search(\n",
    "        query = query,\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        filter_dict={'course': filter_dict }\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ee61d9-5cb7-462d-9566-d9184dbc6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "        You're a course teacher assistant. Answer the question based on the context.\n",
    "        Use only the facts from the context. If relevant information is missing, say you do not know.\n",
    "        Question:\n",
    "        {query}\n",
    "        Context:\n",
    "        {context}\n",
    "        \"\"\".strip()\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context += f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer:{doc['text']}\\n\\n\"\n",
    "    return prompt_template.format(query=query, context=context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08f1432-5543-4ae4-899f-f245b237d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(client, prompt, model='gpt-4.1-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{'role': 'user', 'content': prompt }]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0f81fab-c77e-4145-8439-9f0b71d27aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, verbose_search= False, verbose_prompt = False):\n",
    "    search_results = search(q, index)\n",
    "    if verbose_search:\n",
    "        print(search_results)\n",
    "    prompt = build_prompt(q,search_results)\n",
    "    if verbose_prompt:\n",
    "        print(prompt)\n",
    "    message = llm(client, prompt)\n",
    "    return(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dff30bcf-ae98-44d5-a5ce-5fa6a68d404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teacher assistant. Answer the question based on the context.\n",
      "        Use only the facts from the context. If relevant information is missing, say you do not know.\n",
      "        Question:\n",
      "        Give me a sample dockerfile\n",
      "        Context:\n",
      "        section: Module 1: Docker and Terraform\n",
      "question: Docker - failed to solve with frontend dockerfile.v0: failed to read dockerfile: error from sender: open ny_taxi_postgres_data: permission denied.\n",
      "answer:This happens on Ubuntu/Linux systems when trying to run the command to build the Docker container again.\n",
      "$ docker build -t taxi_ingest:v001 .\n",
      "A folder is created to host the Docker files. When the build command is executed again to rebuild the pipeline or create a new one the error is raised as there are no permissions on this new folder. Grant permissions by running this comtionmand;\n",
      "$ sudo chmod -R 755 ny_taxi_postgres_data\n",
      "Or use 777 if you still see problems. 755 grants write access to only the owner.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: I changed location in dbt, but dbt run still gives me an error\n",
      "answer:Remove the dataset from BigQuery which was created by dbt and run dbt run again so that it will recreate the dataset in BigQuery with the correct location\n",
      "\n",
      "section: error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\n",
      "question: Homework - Qn 5: The partitioned/clustered table isn’t giving me the prediction I expected\n",
      "answer:Ans: Take a careful look at the format of the dates in the question.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: Prefect - Tip: Downloading csv.gz from a url in a prefect environment (sample snippet).\n",
      "answer:@task\n",
      "def download_file(url: str, file_path: str):\n",
      "response = requests.get(url)\n",
      "open(file_path, \"wb\").write(response.content)\n",
      "return file_path\n",
      "@flow\n",
      "def extract_from_web() -> None:\n",
      "file_path = download_file(url=f'{url-filename}.csv.gz',file_path=f'{filename}.csv.gz')\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: I ran dbt run without specifying variable which gave me a table of 100 rows. I ran again with the variable value specified but my table still has 100 rows in BQ.\n",
      "answer:Remove the dataset from BigQuery created by dbt and run again (with test disabled) to ensure the dataset created has all the rows.\n",
      "DBT - Why am I getting a new dataset after running my CI/CD Job? / What is this new dbt dataset in BigQuery?\n",
      "Answer: when you create the CI/CD job, under ‘Compare Changes against an environment (Deferral) make sure that you select ‘ No; do not defer to another environment’ - otherwise dbt won’t merge your dev models into production models; it will create a new environment called ‘dbt_cloud_pr_number of pull request’\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The context does not provide a sample Dockerfile.  \\nTherefore, I do not know a sample Dockerfile based on the given information.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"Give me a sample dockerfile\"\n",
    "rag(q, verbose_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8bbbd-6429-4c11-ba28-558e155a7628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
